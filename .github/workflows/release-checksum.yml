name: Extract Installer Info from GitHub Release

on:
  release:
    types: [published, edited, deleted]
  workflow_dispatch:  # Just to show this workflow in the Actions tab

concurrency:
  group: release-json-update
  cancel-in-progress: false

jobs:
  extract-and-generate:
    # Only run on release events, skip manual triggers
    if: github.event_name != 'workflow_dispatch' && github.event.release.draft == false && !(github.event.action == 'edited' && github.event.changes.draft.from == true)
    runs-on: ubuntu-latest
    permissions:
      contents: write

    steps:
      - name: Checkout repo
        uses: actions/checkout@v4
        with:
          ref: ${{ github.event.repository.default_branch }}

      - name: Set up Node.js
        uses: actions/setup-node@v4
        with:
          node-version: 20

      - name: Cache ".cache" directory (node_modules & downloads)
        uses: actions/cache@v4
        with:
          path: .cache
          key: ${{ runner.os }}-cache-${{ hashFiles('.github/workflows/**.yml') }}
          restore-keys: |
            ${{ runner.os }}-cache-

      - name: Install dependencies
        run: npm install undici@6 @tonyrl/rand-user-agent --prefix .cache

      - name: Extract links, download files, and add/update JSON
        env:
          GITHUB_EVENT_PATH: ${{ github.event_path }}
        run: |
          node <<'EOF'
          const fs = require('fs');
          const path = require('path');
          const crypto = require('crypto');
          const { request } = require(path.resolve('.cache/node_modules/undici'));
          const { randUserAgent } = require(path.resolve('.cache/node_modules/@tonyrl/rand-user-agent'));

          const EVENT_PATH = process.env.GITHUB_EVENT_PATH;
          const STABLE_FILE = path.join('data', 'releases.json');
          const PRE_FILE = path.join('data', 'releases-pre.json');

          // Match .exe or .msi from [name.exe](url) or [file name (.msi)](url)
          const assetRegex = /(installer|portable):\s+\[([^\]]+\.(?:exe|msi)(?:[^\]]+)?)\]\((https?:\/\/[^\)]+)\)/gi;

          function hashContent(content, algo = 'sha256') {
            return crypto.createHash(algo).update(content).digest('hex');
          }

          function getSafeFilename(name, url) {
            try {
              return encodeURIComponent(name);
            } catch {
              return encodeURIComponent(path.basename(url));
            }
          }

          async function downloadBuffer(url, maxRetries = 3) {
            const delay = ms => new Promise(res => setTimeout(res, ms));

            for (let attempt = 1; attempt <= maxRetries; attempt++) {
              try {
                const { body, headers, statusCode } = await request(url, {
                  maxRedirections: 5,
                  headers: {
                    'User-Agent': randUserAgent("desktop", "chrome", "linux"),
                    'Accept': '*/*'
                  }
                });
                if (statusCode !== 200) {
                  throw new Error(`HTTP ${statusCode}`);
                }
                const chunks = [];
                for await (const chunk of body) {
                  chunks.push(chunk);
                }
                const buffer = Buffer.concat(chunks);

                // Detect HTML response pretending to be a binary
                if (headers['content-type']?.includes('text/html') || buffer.slice(0, 100).toString().toLowerCase().includes('<!doctype html')) {
                  throw new Error(`Downloaded content looks like HTML instead of binary (content-type: ${headers['content-type'] || 'unknown'})`);
                }

                return buffer;
              } catch (err) {
                console.warn(`âš ï¸ Attempt ${attempt} failed for "${url}": ${err.message}`);
                if (attempt < maxRetries) {
                  await delay(1000 * attempt);
                } else {
                  console.error(`âŒ All ${maxRetries} attempts failed for ${url}`);
                  return null;
                }
              }
            }
          }

          async function getOrCacheAsset(descDigest, name, url) {
            const downloadDir = path.join('.cache', 'downloads', descDigest);
            fs.mkdirSync(downloadDir, { recursive: true });

            const safeName = getSafeFilename(name, url);
            const cachePath = path.join(downloadDir, safeName);
            let buffer;

            if (fs.existsSync(cachePath)) {
              buffer = fs.readFileSync(cachePath);
              console.log(`â™»ï¸ Reused cached asset: ${cachePath}`);
            } else {
              try {
                buffer = await downloadBuffer(url);
                fs.writeFileSync(cachePath, buffer);
                console.log(`â¬‡ï¸ Downloaded and cached: ${cachePath}`);
              } catch (err) {
                console.error(`âŒ Failed to fetch ${url} for ${name}: ${err.message}`);
                return null;
              }
            }

            return {
              name,
              url,
              size: buffer.length,
              digest: {
                sha256: hashContent(buffer),
                sha1: hashContent(buffer, 'sha1'),
                md5: hashContent(buffer, 'md5')
              }
            };
          }

          async function getAssetInfoFromBody(desc, descDigest) {
            const lines = desc.split(/\r?\n/);
            let currentArch = null;
            const assets = [];

            for (const line of lines) {
              // Detect architecture headings (e.g., **x86** or **x64**)
              const archMatch = /^\*\*\s*(x86|x64)\s*\*\*/i.exec(line.trim());
              if (archMatch) {
                currentArch = archMatch[1];
                continue;
              }

              // Match asset line
              const match = assetRegex.exec(line);
              if (match) {
                const [, type, name, url] = match;
                const baseAsset = await getOrCacheAsset(descDigest, name, url);
                if (baseAsset) {
                  const asset = currentArch
                    ? { arch: currentArch, type, ...baseAsset }
                    : { type, ...baseAsset };
                  assets.push(asset);
                }
              }
            }
            return assets;
          }
          async function processRelease(release, action) {
            console.log(`ðŸ“¢ Action: ${action.toUpperCase()} | Version: ${release.tag_name}`);

            fs.mkdirSync('data', { recursive: true });

            const file = release.prerelease ? PRE_FILE : STABLE_FILE;
            const fileExists = fs.existsSync(file);
            const existing = fileExists ? JSON.parse(fs.readFileSync(file, 'utf8')) : [];
            const version = release.tag_name.replace(/^v/i, '');

            if (action === 'deleted') {
              if (!fileExists) {
                console.log(`â„¹ï¸ ${file} does not exist, nothing to remove`);
                return;
              }

              const updated = existing.filter(e => e.version !== version);
              if (updated.length === existing.length) {
                console.log(`â„¹ï¸ Version ${version} not found in ${file}, nothing to remove`);
                return;
              }

              fs.writeFileSync(file, JSON.stringify(updated, null, 2));
              console.log(`ðŸ—‘ï¸ Removed version ${version} from ${file}`);
              return;
            }

            const desc = release.body || '';
            const descDigest = hashContent(desc);
            const fullDigest = 'sha256:' + descDigest;

            const existingIndex = existing.findIndex(e => e.version === version);
            const prevDigest = existingIndex !== -1 ? existing[existingIndex].desc_digest : null;

            // If the release is already in the file and the `desc_digest` hasn't changed
            if (existingIndex !== -1 && prevDigest === fullDigest) {
              console.log(`â†©ï¸ Skipping unchanged version ${version}`);
              return;
            }

            const assets = await getAssetInfoFromBody(desc, descDigest);
            if (!assets.length) {
              console.warn(`âš ï¸ No valid assets found in release ${version}`);
            }

            const entry = {
              version,
              url: release.html_url,
              desc_digest: fullDigest,
              assets
            };

            const updated = [...existing];  // clone
            if (existingIndex === -1) {
              console.log(`âž• Adding new version ${version}`);
              updated.unshift(entry); // Add to top
            } else {
              console.log(`ðŸ”„ Updating modified version ${version}`);
              updated[existingIndex] = entry;
            }

            const newJson = JSON.stringify(updated, null, 2);

            // Final check, prevents unnecessary commit when thereâ€™s no actual data change
            if (fileExists && fs.readFileSync(file, 'utf8') === newJson) {
              console.log(`â†©ï¸ ${file} unchanged, not rewritten.`);
              return;
            }

            fs.writeFileSync(file, newJson);
            console.log(`âœ… ${fileExists ? 'Updated' : 'Created'} ${file} with ${updated.length} release(s)`);
          }

          async function main() {
            const event = JSON.parse(fs.readFileSync(EVENT_PATH, 'utf8'));
            const release = event.release;

            if (!release || !release.tag_name) {
              throw new Error("No release info found.");
            }

            await processRelease(release, event.action);
          }

          main().catch(err => {
            console.error(err);
            process.exit(1);
          });
          EOF

      - name: Check for newly created or updated release JSON files
        id: commitinfo
        run: |
          shopt -s nullglob
          files=(data/releases*.json)
          git add "${files[@]}"

          # Default message
          echo "message=ðŸ¤– Update release info for ${{ github.ref_name }}" >> "$GITHUB_OUTPUT"

          # Check if any files are newly added
          files_added=$(git diff --cached --name-status -- data/releases*.json | grep '^A' | wc -l)
          if [ "$files_added" -gt 0 ]; then
            echo "message=ðŸ¤– Initial release info" >> "$GITHUB_OUTPUT"
          fi

          # Check if any lines were removed (deleted release entry)
          files_removed=$(git diff --cached --numstat -- data/releases*.json | awk '$2 > $1 {exit 1}' && echo 0 || echo 1)
          if [ "$files_removed" -eq 1 ]; then
            echo "message=chore: sync release JSON files (remove old version)" >> "$GITHUB_OUTPUT"
          fi

      - name: Commit release info JSON
        uses: stefanzweifel/git-auto-commit-action@v5
        with:
          commit_message: ${{ steps.commitinfo.outputs.message }}
          file_pattern: data/releases*.json
